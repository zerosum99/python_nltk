{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 기본 단어형 찾기 (stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 줄 번호 넣기\n",
    "\n",
    "    control 키 + m + l\n",
    "    \n",
    "    라인 번호가 생긴 곳에 다시 한번 더 누르면 라인 번호가 사라진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.4'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nltk.stem.api.StemmerI,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PorterStemmer.__bases__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nltk.stem.api.StemmerI,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LancasterStemmer.__bases__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nltk.stem.api.StemmerI,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RegexpStemmer.__bases__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nltk.stem.api.StemmerI,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SnowballStemmer.__bases__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PosterStemmer 클래스 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARTIN_EXTENSIONS\n",
      "NLTK_EXTENSIONS\n",
      "ORIGINAL_ALGORITHM\n",
      "stem\n",
      "unicode_repr\n"
     ]
    }
   ],
   "source": [
    "for i in dir(PorterStemmer) :\n",
    "    if not i.startswith(\"_\") :\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function stem in module nltk.stem.porter:\n",
      "\n",
      "stem(self, word)\n",
      "    Strip affixes from the token and return the stem.\n",
      "    \n",
      "    :param token: The token that should be stemmed.\n",
      "    :type token: str\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(PorterStemmer.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'studi'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_porter = PorterStemmer() \n",
    "s_porter.stem(\"studying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'student'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_porter.stem(\"student\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LancsterStemmer 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default_rule_tuple\n",
      "parseRules\n",
      "stem\n",
      "unicode_repr\n"
     ]
    }
   ],
   "source": [
    "for i in dir(LancasterStemmer) :\n",
    "    if not i.startswith(\"_\") :\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'study'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_lancaster = LancasterStemmer() \n",
    "s_lancaster.stem(\"studying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stud'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_lancaster.stem(\"student\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SnowballStemmer 클래스 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "languages\n",
      "stem\n"
     ]
    }
   ],
   "source": [
    "for i in dir(SnowballStemmer) :\n",
    "    if not i.startswith(\"_\") :\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'porter',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SnowballStemmer.languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'studi'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_snowball = SnowballStemmer(\"english\") \n",
    "s_snowball.stem(\"studying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'student'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_snowball.stem(\"student\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 단어의 원형 복원 이해 lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordNetLemmatizer 클래스 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(object,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordNetLemmatizer.__bases__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmatize\n",
      "unicode_repr\n"
     ]
    }
   ],
   "source": [
    "for i in dir(WordNetLemmatizer) :\n",
    "    if not i.startswith(\"_\") :\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function lemmatize in module nltk.stem.wordnet:\n",
      "\n",
      "lemmatize(self, word, pos='n')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(WordNetLemmatizer.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "studying\n"
     ]
    }
   ],
   "source": [
    "lemma_ = WordNetLemmatizer( )\n",
    "\n",
    "print(lemma_.lemmatize(\"studying\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study\n"
     ]
    }
   ],
   "source": [
    "print(lemma_.lemmatize(\"studying\",pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6 Stanford  자연어 처리 확인하기.ipynb\n",
      "1 토큰화 및 정규화 이해하기.ipynb\n",
      "2 실제 빈도에 따른 그래프를 그리기.ipynb\n",
      "3 gram을 이용한 단어의 빈도 이해하기.ipynb\n",
      "4 parts of speech 단어에 대한 품사 처리하기 .ipynb\n",
      "5 어근 등 정규화하기   nltk.stem .ipynb\n",
      "8 기본 단어형태 찾기  단어의 복원 이해.ipynb\n",
      "FreqDist.png\n",
      "README.md\n",
      "book 모듈 이해하기 .ipynb\n",
      "brown_corpus.png\n",
      "common structure.png\n",
      "corpus 1.png\n",
      "corpus 2.png\n",
      "corpus 3.png\n",
      "corpus 4.png\n",
      "corpus function.png\n",
      "corpus reuters 이해하기.ipynb\n",
      "corpus 모듈  download 처리.ipynb\n",
      "corpus 모듈 이해하기  brown .ipynb\n",
      "corpus 모듈 이해하기  wordnet.ipynb\n",
      "corpus 모듈 이해하기 .ipynb\n",
      "corpus 모듈 이해하기 gutenberg.ipynb\n",
      "data\n",
      "ngram 이해하기.ipynb\n",
      "nltk FreqDist 클래스 이해하기.ipynb\n",
      "nltk Text 클래스 이해하기.ipynb\n",
      "nltk 토근화  기본 이해하기 _20170804.ipynb\n",
      "nltk 정규표현식 처리.ipynb\n",
      "nltk.tokenize.regexp 모듈 내의 클래스.ipynb\n",
      "nltk.tokenize.simple 모듈 내의 토큰화 클래스.ipynb\n",
      "pos.png\n",
      "tokenization.png\n",
      "unitarea_code.xls\n",
      "whitespace.png\n",
      "wordstem.png\n",
      "용어 정의 .ipynb\n",
      "코퍼스 모듈이해하기 words.ipynb\n",
      "태깅달기 nltk.tag .ipynb\n",
      "정규표현식에 따른 토큰화 처리.ipynb\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
